#version: "3.9"

services:
  postgres:
    image: postgres:14.3
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
      
  kafka:
    image: apache/kafka-native:4.1.1

    environment:
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_NODE_ID=1
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CLUSTER_ID=mk00000000000000000000
      - KAFKA_LOG_DIRS=/var/lib/kafka/data
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
    ports:
      - "9092:9092"
    volumes:
      - kafkadata:/var/lib/kafka/data
    # Note: apache/kafka-native image in some tags does not include cli scripts on PATH,
    # so a script-based healthcheck is unreliable. We rely on app/consumer retry logic instead.

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=["http://elasticsearch:9200"]
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  # Lightweight log ingestion so you can explore logs in Kibana Discover without Fleet/Integrations
  elastic-agent:
    image: docker.elastic.co/beats/elastic-agent:8.15.3
    container_name: elastic-agent
    user: root
    volumes:
      # Read Docker JSON logs from the host
      - /media/tim/docker/containers:/var/lib/docker/containers:ro
      # Provide standalone agent config
      - ./docker/elastic-agent.yml:/usr/share/elastic-agent/elastic-agent.yml:ro
    environment:
      - ELASTIC_AGENT_CLOUD=false
    depends_on:
      - elasticsearch
    restart: unless-stopped
    ports:
      - "5066:5066"  # agent monitoring endpoint (optional)

  app_loc1:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: app_loc1
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc1
      - ROLE_HEADER=X-Role
      - FUZZY_HIT_LIMIT=25
      - RETENTION_DAYS=365
      - KAFKA_BOOTSTRAP=kafka:9092
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - DEBUG=1
      - SECRET_KEY=dev-secret
      - LOAD_SAMPLE_DATA=1
    command: ["gunicorn", "-b", "0.0.0.0:8000", "sins.wsgi:application"]
    ports:
      - "8001:8000"
    depends_on:
      - kafka
      - elasticsearch
      - elastic-agent

  app_loc2:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: app_loc2
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc2
      - ROLE_HEADER=X-Role
      - FUZZY_HIT_LIMIT=25
      - RETENTION_DAYS=365
      - KAFKA_BOOTSTRAP=kafka:9092
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - DEBUG=1
      - SECRET_KEY=dev-secret
      - LOAD_SAMPLE_DATA=1
    command: ["gunicorn", "-b", "0.0.0.0:8000", "sins.wsgi:application"]
    ports:
      - "8002:8000"
    depends_on:
      - kafka
      - elasticsearch
      - elastic-agent

  app_loc3:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: app_loc3
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc3
      - ROLE_HEADER=X-Role
      - FUZZY_HIT_LIMIT=25
      - RETENTION_DAYS=365
      - KAFKA_BOOTSTRAP=kafka:9092
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - DEBUG=1
      - SECRET_KEY=dev-secret
      - LOAD_SAMPLE_DATA=1
    command: ["gunicorn", "-b", "0.0.0.0:8000", "sins.wsgi:application"]
    ports:
      - "8003:8000"
    depends_on:
      - kafka
      - elasticsearch
      - elastic-agent

  consumer_loc1:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: consumer_loc1
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc1
      - KAFKA_BOOTSTRAP=kafka:9092
      - DEBUG=1
      - SECRET_KEY=dev-secret
    command: ["python", "manage.py", "consume_events"]
    depends_on:
      - kafka
    restart: unless-stopped

  consumer_loc2:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: consumer_loc2
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc2
      - KAFKA_BOOTSTRAP=kafka:9092
      - DEBUG=1
      - SECRET_KEY=dev-secret
    command: ["python", "manage.py", "consume_events"]
    depends_on:
      - kafka
    restart: unless-stopped

  consumer_loc3:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: consumer_loc3
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc3
      - KAFKA_BOOTSTRAP=kafka:9092
      - DEBUG=1
      - SECRET_KEY=dev-secret
    command: ["python", "manage.py", "consume_events"]
    depends_on:
      - kafka
    restart: unless-stopped

  retention_worker:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: retention_worker
    environment:
      - DJANGO_SETTINGS_MODULE=sins.settings
      - LOCATION_ID=loc1
      - DEBUG=1
      - SECRET_KEY=dev-secret
    command: ["sh", "-c", "while true; do python manage.py cleanup_customers; sleep 86400; done"]
    depends_on:
      - app_loc1

volumes:
  esdata:
  kafkadata:
